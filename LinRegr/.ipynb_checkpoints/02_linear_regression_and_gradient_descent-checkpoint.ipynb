{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqEpGyyyGE1Z",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "## Solving the linear regression problem with gradient descent\n",
    "\n",
    "Today we rewise the linear regression algorithm and it's gradient solution.\n",
    "\n",
    "Your main goal will be to __derive and implement the gradient of MSE, MAE, L1 and L2 regularization terms__ respectively in general __vector form__ (when both single observation $\\mathbf{x}_i$ and corresponding target value $\\mathbf{y}_i$ are vectors).\n",
    "\n",
    "This techniques will be useful later in Deep Learning module of our course as well.\n",
    "\n",
    "We will work with [Boston housing prices dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) subset, which have been preprocessed for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "BpLXB2vdi6mN",
    "outputId": "9a19d0ff-caaf-4f89-ac9d-22a7ebecd6ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nIf you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\\nYou can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\n",
    "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
    "'''\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/22s_msai/homeworks/assignment0_02_lin_reg/loss_and_derivatives.py\n",
    "# !wget https://github.com/girafe-ai/ml-course/blob/22f_basic/homeworks/assignment0_02_lin_reg/boston_subset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lQUR89nGE1f",
    "outputId": "d318a03a-9b69-4170-d1dc-42beffcf6753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OGf3ShTNGE1q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('boston_subset.json', 'r') as iofile:\n",
    "    dataset = json.load(iofile)\n",
    "feature_matrix = np.array(dataset['data'])\n",
    "targets = np.array(dataset['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIUU1cOZGE10"
   },
   "source": [
    "## Warming up: matrix differentiation\n",
    "_You will meet these questions later in Labs as well, so we highly recommend to answer them right here._\n",
    "\n",
    "Credits: this theoretical part is copied from [YSDA Practical_DL course](https://github.com/yandexdataschool/Practical_DL/tree/spring2019/homework01) homework01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvrZt_xNGE12"
   },
   "source": [
    "Since it easy to google every task please please please try to understand what's going on. The \"just answer\" thing will not be  counted, make sure to present derivation of your solution. It is absolutely OK if you will find an answer on web then just exercise in $\\LaTeX$ copying it into here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty4m156yGE15"
   },
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
    "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8StFOCFGE17"
   },
   "source": [
    "#### Inline question 1\n",
    "$$  \n",
    "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = 2x\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "Explanation: \n",
    "\\\\dy = d[Tr(x^Tx)] = Tr(d[x^tx]) = Tr(x^Tdx + dx^Tx) = Tr(2x^Tdx) \\Rightarrow \\frac{dy}{dx} = (2x^T)^T = 2x \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtnNCP4JGE19"
   },
   "source": [
    "#### Inline question 2\n",
    "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ \n",
    "\n",
    "$$\n",
    "\\frac{dy}{dA} = B^T\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "Explanation:\n",
    "\\\\y = trAB = tr\n",
    "\\begin{pmatrix}\n",
    "\\overrightarrow{\\rm a_1}\\\\\n",
    "\\overrightarrow{\\rm a_2}\\\\\n",
    "\\vdots \\\\\n",
    "\\overrightarrow{\\rm a_N}\n",
    "\\end{pmatrix}\n",
    ".\n",
    "\\begin{pmatrix}\n",
    "\\overrightarrow{\\rm b_1}^{\\uparrow} & \\overrightarrow{\\rm b_2}^{\\uparrow} & \\dots & \\overrightarrow{\\rm b_N}^{\\uparrow}\n",
    "\\end{pmatrix} = tr\n",
    "\\begin{pmatrix}\n",
    "\\overrightarrow{\\rm a_1}^T\\overrightarrow{\\rm b_1} & \\dots & \\overrightarrow{\\rm a_1}^T\\overrightarrow{\\rm b_N}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\overrightarrow{\\rm a_N}^T\\overrightarrow{\\rm b_1} & \\dots & \\overrightarrow{\\rm a_N}^T\\overrightarrow{\\rm b_N}\n",
    "\\end{pmatrix} = \\sum_{i=1}^Na_{1i}b_{i1} + \\dots + \\sum_{i=1}^Na_{Ni}b_{iN} \\Rightarrow \\frac{dy}{da_{ij}} = b_{ji} \\Rightarrow \\frac{dy}{dA} = B^T \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWfcC7_dGE2A"
   },
   "source": [
    "#### Inline question 3\n",
    "$$  \n",
    "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = Ac\n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "Explanation:\n",
    "\\\\\\triangle{y} = y(x+\\triangle{x})-y(x) = (x+\\triangle{x})^TAc - x^TAc = \\triangle{x^T}Ac = \n",
    "\\begin{pmatrix}\n",
    "\\triangle{x_1} & \\triangle{x_2} & \\dots & \\triangle{x_N} \n",
    "\\end{pmatrix}.\n",
    "\\begin{pmatrix}\n",
    "a_1^{\\uparrow} & a_2^{\\uparrow} & \\dots & a_N^{\\uparrow} \n",
    "\\end{pmatrix}.\n",
    "\\begin{pmatrix}\n",
    "c_1 \\\\\n",
    "c_2 \\\\\n",
    "\\vdots \\\\\n",
    "c_N \n",
    "\\end{pmatrix}\n",
    "= c_1\\sum_{i=1}^N{\\triangle{x_i}a_{i1}} + \\dots + c_N\\sum_{i=1}^N{\\triangle{x_i}a_{iN}} \\Rightarrow \\frac{\\partial{y}}{\\partial{x_i}} = c_1a_{i1} + c_2a_{i2} + \\dots + c_Na_{iN} \\Rightarrow \\frac{dy}{dx} = A^Tc \n",
    "$$\n",
    "$$$$\n",
    "$$\n",
    "\\frac{dy}{dA} = \\sum_{j=1}^N\\sum_{i=1}^Nx_ic_j\n",
    "$$\n",
    "$$$$\n",
    "Hint for the latter (one of the ways): use *ex. 2* result and the fact \n",
    "$$\n",
    "tr(ABC) = tr (CAB)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbBc_5FhGE2B"
   },
   "source": [
    "## Loss functions and derivatives implementation\n",
    "You will need to implement the methods from `loss_and_derivatives.py` to go further.\n",
    "__In this assignment we ignore the bias term__, so the linear model takes simple form of \n",
    "$$\n",
    "\\hat{\\mathbf{y}} = XW\n",
    "$$\n",
    "where no extra column of 1s is added to the $X$ matrix.\n",
    "\n",
    "Implement the loss functions, regularization terms and their derivatives with reference to (w.r.t.) weight matrix. \n",
    "\n",
    "__Once again, you can assume that linear model is not required for bias term for now. The dataset is preprocessed for this case.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-CX9dTLGE1y"
   },
   "source": [
    "Autoreload is a great stuff, but sometimes it does not work as intended. The code below aims to fix that. __Do not forget to save your changes in the `.py` file before reloading the desired functions.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dtELlRTOGE2E",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# This dirty hack might help if the autoreload has failed for some reason\n",
    "try:\n",
    "    del LossAndDerivatives\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from loss_and_derivatives import LossAndDerivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q91hBl5pi6me"
   },
   "source": [
    "Mention, that in this case we compute the __MSE__ and __MAE__ for vector __y__. In the reference implementation we are averaging the error along the __y__ dimentionality as well.\n",
    "\n",
    "E.g. for residuals vector $[1., 1., 1., 1.]$ the averaged error value will be $\\frac{1}{4}(1. + 1. + 1. + 1.)$ \n",
    "\n",
    "This may be needed to get the desired mutliplier for loss functions derivatives. You also can refer to the `.mse` method implementation, which is already available in the `loss_and_derivatives.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "71VCxUwHGE2L"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMN81aYyGE2T"
   },
   "source": [
    "Here come several asserts to check yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KKUYnPWuGE2V"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets\n",
    "\n",
    "# Repeating data to make everything multi-dimentional\n",
    "w = np.vstack([w[None, :] + 0.27, w[None, :] + 0.22, w[None, :] + 0.45, w[None, :] + 0.1]).T\n",
    "y_n = np.hstack([y_n[:, None], 2*y_n[:, None], 3*y_n[:, None], 4*y_n[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtkO4hWYGE2c",
    "outputId": "44d6cd87-4db5-430d-fc92-16557c19ebb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE derivative:\n",
      "[[ 7.32890068 12.88731311 18.82128365 23.97731238]\n",
      " [ 9.55674399 17.05397661 24.98807528 32.01723714]] \n",
      "\n",
      "L2 reg derivative:\n",
      "[[2.54 2.44 2.9  2.2 ]\n",
      " [2.54 2.44 2.9  2.2 ]]\n"
     ]
    }
   ],
   "source": [
    "reference_mse_derivative = np.array([\n",
    "    [ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
    "    [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]\n",
    "])\n",
    "reference_l2_reg_derivative = np.array([\n",
    "    [2.54, 2.44, 2.9 , 2.2 ],\n",
    "    [2.54, 2.44, 2.9 , 2.2 ]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mse_derivative,\n",
    "    LossAndDerivatives.mse_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MSE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l2_reg_derivative,\n",
    "    LossAndDerivatives.l2_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L2 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MSE derivative:\\n{} \\n\\nL2 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mse_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l2_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvx6Pkkdi6mh",
    "outputId": "26149c6b-56da-4c5d-a651-801edf3ea922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE derivative:\n",
      "[[0.19708867 0.19621798 0.19621798 0.19572906]\n",
      " [0.25574138 0.25524507 0.25524507 0.25406404]] \n",
      "\n",
      "L1 reg derivative:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "reference_mae_derivative = np.array([\n",
    "    [0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
    "    [0.25574138, 0.25524507, 0.25524507, 0.25406404]\n",
    "])\n",
    "reference_l1_reg_derivative = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 1., 1.]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mae_derivative,\n",
    "    LossAndDerivatives.mae_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MAE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l1_reg_derivative,\n",
    "    LossAndDerivatives.l1_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L1 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MAE derivative:\\n{} \\n\\nL1 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mae_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l1_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJcSPj8UGE20"
   },
   "source": [
    "### Gradient descent on the real data\n",
    "Here comes small loop with gradient descent algorithm. We compute the gradient over the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "On6aSWuIGE21"
   },
   "outputs": [],
   "source": [
    "def get_w_by_grad(X, Y, w_0, loss_mode='mse', reg_mode=None, lr=0.05, n_steps=100, reg_coeff=0.05):\n",
    "    if loss_mode == 'mse':\n",
    "        loss_function = LossAndDerivatives.mse\n",
    "        loss_derivative = LossAndDerivatives.mse_derivative\n",
    "    elif loss_mode == 'mae':\n",
    "        loss_function = LossAndDerivatives.mae\n",
    "        loss_derivative = LossAndDerivatives.mae_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
    "    \n",
    "    if reg_mode is None:\n",
    "        reg_function = LossAndDerivatives.no_reg\n",
    "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
    "    elif reg_mode == 'l2':\n",
    "        reg_function = LossAndDerivatives.l2_reg\n",
    "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
    "    elif reg_mode == 'l1':\n",
    "        reg_function = LossAndDerivatives.l1_reg\n",
    "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
    "    \n",
    "    \n",
    "    w = w_0.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
    "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        if gradient_norm > 5.:\n",
    "            gradient = gradient / gradient_norm * 5.\n",
    "        w -= lr * gradient\n",
    "        \n",
    "        if i % 25 == 0:\n",
    "            print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHIEihaWi6mi"
   },
   "source": [
    "Let's check how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A1pyDIyqGE25"
   },
   "outputs": [],
   "source": [
    "# Initial weight matrix\n",
    "w = np.ones((2,1), dtype=float)\n",
    "y_n = targets[:, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erTRQiAFGE29",
    "outputId": "43399bdb-cbbd-4bf3-eee3-9028cd973a1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=0, loss=231.28353984777308,\n",
      "gradient values=[[3.03360308]\n",
      " [3.97457575]]\n",
      "\n",
      "Step=25, loss=58.512903511682715,\n",
      "gradient values=[[2.28551977]\n",
      " [4.44706638]]\n",
      "\n",
      "Step=50, loss=48.29584498872882,\n",
      "gradient values=[[-0.89558132]\n",
      " [ 0.76425616]]\n",
      "\n",
      "Step=75, loss=47.292783042717005,\n",
      "gradient values=[[-0.48111511]\n",
      " [ 0.40907079]]\n",
      "\n",
      "Step=100, loss=47.00419092029711,\n",
      "gradient values=[[-0.25806412]\n",
      " [ 0.21942022]]\n",
      "\n",
      "Step=125, loss=46.921159712801064,\n",
      "gradient values=[[-0.1384223 ]\n",
      " [ 0.11769421]]\n",
      "\n",
      "Step=150, loss=46.897270698227686,\n",
      "gradient values=[[-0.07424796]\n",
      " [ 0.06312967]]\n",
      "\n",
      "Step=175, loss=46.890397559386315,\n",
      "gradient values=[[-0.03982566]\n",
      " [ 0.03386195]]\n",
      "\n",
      "Step=200, loss=46.88842007984702,\n",
      "gradient values=[[-0.02136197]\n",
      " [ 0.01816312]]\n",
      "\n",
      "Step=225, loss=46.88785113668749,\n",
      "gradient values=[[-0.01145829]\n",
      " [ 0.00974247]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_grad = get_w_by_grad(x_n, y_n, w, loss_mode='mse', reg_mode='l2', n_steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooc_Bkf4i6mk"
   },
   "source": [
    "### Comparing with `sklearn`\n",
    "Finally, let's compare our model with `sklearn` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Z_-qOIlvi6mk"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaFSPFT8i6mk",
    "outputId": "5f138912-353e-482e-88e5-c6b876606a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn linear regression implementation delivers MSE = 42.53541245128315\n"
     ]
    }
   ],
   "source": [
    "lr = Ridge(alpha=0.05)\n",
    "lr.fit(x_n, y_n)\n",
    "print('sklearn linear regression implementation delivers MSE = {}'.format(np.mean((lr.predict(x_n) - y_n)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Gse1m4nyGE3C",
    "outputId": "f00c5684-f42d-42c0-cc5e-63817cc81baf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_n[:, -1], y_n[:, -1])\n",
    "plt.scatter(x_n[:, -1], x_n.dot(w_grad)[:, -1], color='orange', label='Handwritten linear regression', linewidth=5)\n",
    "plt.scatter(x_n[:, -1], lr.predict(x_n), color='cyan', label='sklearn Ridge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbrPP66ai6ml"
   },
   "source": [
    "While the solutions may look like a bit different, remember, that handwritten linear regression was unable to fit the bias term, it was equal to $0$ by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GgeWdBmGE3H"
   },
   "source": [
    "### Submit your work\n",
    "To submit your work you need to log into Yandex contest (link will be provided later) and upload the `loss_and_derivatives.py` file for the corresponding problem."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
